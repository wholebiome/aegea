#!/usr/bin/env python3
"""
Deployment manager daemon for aegea deploy.

Launched by systemd, which sets the environment arguments:
    REPOORG
    REPONAME
    REPOBRANCH
    MAKETARGET
    MAKERELOADTARGET

Example of manual launch for debugging:
    REPOORG=wholebiome \
    REPONAME=wb_deploy_example \
    REPOBRANCH=branchtest \
    MAKETARGET=mydeploy \
    MAKERELOADTARGET=myreload \
    DEPLOY_LOCATION="/opt" \
    aegea-deploy-pilot

To manually post to the SNS topic this listens to, see "manual_sns_topic_post.py".

For build repo related code, see "deployer.py".

For more information, see ``aegea deploy --help``.
"""
from __future__ import absolute_import, division, print_function, unicode_literals

import os, sys, json, logging, signal
import boto3, requests
import imp
deployer = imp.load_source('aegea_deployer', '/usr/lib/aegea/deployer.py')

class ARN:
    fields = "arn partition service region account_id resource".split()
    def __init__(self, arn="arn:aws::::", **kwargs):
        self.__dict__.update(dict(zip(self.fields, arn.split(":", 5)), **kwargs))
    def __str__(self):
        return ":".join(getattr(self, field) for field in self.fields)

def get_metadata(path):
    return requests.get("http://169.254.169.254/latest/meta-data/{}".format(path)).content.decode()

def gather_aws_settings():
    global aws_settings

    aws_settings = {
        "az": get_metadata("placement/availability-zone"),
        "instance_id": get_metadata("instance-id"),
        "account_id": ARN(json.loads(get_metadata("iam/info"))["InstanceProfileArn"]).account_id
    }

    return aws_settings

def aws_init(aws_settings, deployment_settings):
    global session, sqs, sns, s3, queue
    global topic_name, topic_arn, queue_name

    session = boto3.Session(region_name=aws_settings["az"][:-1])
    sqs, sns, s3 = session.resource("sqs"), session.resource("sns"), session.resource("s3")

    # Get SNS topic
    topic_name = "github-{}-{}-events".format(deployment_settings["org"],
                                              deployment_settings["name"])
    topic_arn = str(ARN(service="sns",
            region=sns.meta.client.meta.region_name,
            account_id=aws_settings["account_id"],
            resource=topic_name))
    topic = sns.Topic(topic_arn)

    # Get or create SQS queue
    queue_name = "{on}-{rn}-{bn}-{iid}".format(on=deployment_settings["org"],
                                               rn=deployment_settings["name"],
                                               bn=deployment_settings["branch"],
                                               iid=aws_settings["instance_id"])
    queue = None
    try:
        queue = sqs.get_queue_by_name(QueueName=queue_name)
        logging.info("Reusing queue: {}".format(queue_name))
    except:
        pass
    if queue is None:
        logging.info("Creating queue: {}".format(queue_name))
        queue = sqs.create_queue(QueueName=queue_name)

    # Ensure queue has cooperative policy
    policy = dict(Version="2012-10-17",
                  Statement=[dict(Effect="Allow", Principal="*", Action="sqs:SendMessage",
                                  Resource=queue.attributes["QueueArn"],
                                  Condition=dict(ArnEquals={"aws:SourceArn": topic.arn}))])
    # In multi-node deployments, use DelaySeconds to stagger builds
    queue.set_attributes(Attributes=dict(Policy=json.dumps(policy),
                                         MessageRetentionPeriod="43200",
                                         VisibilityTimeout="43200"))
    # Subscribe queue to topic
    topic.subscribe(Protocol="sqs", Endpoint=queue.attributes["QueueArn"])

def update_status(**updates):
    try:
        bucket = s3.Bucket("deploy-status-" + aws_settings["account_id"])
        return bucket.put_object(Key=os.path.join(os.path.basename(queue.url), "status"),
                                 Body=json.dumps(updates).encode("utf-8"))
    except Exception as e:
        logging.error(e)

def deploy_with_status_updates():
    try:
        ref = deployer.get_deploy_desc(deployment_settings)
        commit = deployer.get_deploy_rev(deployment_settings)

        update_status(Status="Deploying " + deployment_settings["branch"],
                      Ref=ref, Commit=commit)
        deployer.deploy(deployment_settings)
        update_status(Status="OK",
                      Ref=ref, Commit=commit)
    except Exception:
        update_status(Status="Failed",
                      Ref=ref, Commit=commit)
        raise

# systemd service reload
def deployment_reloaded():
    logging.info("Deployment daemon reloaded.")
    deploy_with_status_updates()

# systemd service stop
def deployment_stopped():
    logging.info("Deployment daemon stopped.")

if __name__ == "__main__":
    # Debug trace with:
    # import ipdb; ipdb.set_trace()

    # systemd: ExecReload=/bin/kill -USR1 $MAINPID ("service reload")
    # systemd: ExecStop=/bin/kill -USR2 $MAINPID ("service stop" or "service restart")
    signal.signal(signal.SIGUSR1, lambda signum, frame: deployment_reloaded())
    signal.signal(signal.SIGUSR2, lambda signum, frame: deployment_stopped())

    logging.basicConfig(level=logging.INFO)

    deployment_settings = deployer.gather_deployment_settings()
    aws_settings = gather_aws_settings()

    aws_init(aws_settings, deployment_settings)

    logging.info("Aegea-deploy-pilot invoked with deployment settings:", deployment_settings)
    logging.info("Enviroment variables:", os.environ)
    logging.info("AWS settings:", aws_settings)
    logging.info("SNS Topic Name: {}".format(topic_name))
    logging.info("SQS Queue Name: {}".format(queue_name))

    try:
        logging.info("Running initial deployment...")
        deploy_with_status_updates()
    except Exception as e:
        logging.error("Failed to run initial deployment: %s", e)

    # Poll SQS queue for events
    # http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-how-it-works.html
    # http://boto3.readthedocs.io/en/latest/guide/sqs.html#processing-messages
    while True:
        messages = queue.receive_messages(WaitTimeSeconds=20)

        if len(messages) > 0:
            logging.info("Received {} queue message(s) (topic: {}, queue: {}):".format(len(messages), topic_name, queue_name))

            try:
                deployer.handle_github_messages(messages)
            except Exception as e:
                logging.error("Deployment handler failed to process messages: %s", e)

            for m in messages:
                m.delete()